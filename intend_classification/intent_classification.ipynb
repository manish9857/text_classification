{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sklearn.metrics as m\n",
    "from sklearn.externals import joblib\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(filepath):\n",
    "    \"\"\" Parse the text file and create a dataframe with sentences (for input data)\n",
    "    and all the intents (for target data)\"\"\"\n",
    "    sentences, sentence_intents, unique_intents = [], [], []\n",
    "    data_dict = {}\n",
    "    with open(filepath,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            sentence = re.findall(\"(?<=BOS)(.*)(?=EOS)\", line)\n",
    "            sentences.extend(sentence)\n",
    "            intent = re.findall(\"(I-\\S+)\",line)\n",
    "            sentence_intents.append(intent)\n",
    "            unique_intents.extend(intent)\n",
    "    data_dict['sentences'] = sentences\n",
    "    data_dict['intent_list'] = sentence_intents\n",
    "    for intent in unique_intents:\n",
    "        intent_col = [list(set(intent_list)).count(intent) for intent_list in sentence_intents]\n",
    "        data_dict[intent]=intent_col\n",
    "    return pd.DataFrame(data_dict), unique_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, unique_intents = create_dataframe(\"./data/atis-2.train.w-intent.iob.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>intent_list</th>\n",
       "      <th>I-round_trip</th>\n",
       "      <th>I-fare_amount</th>\n",
       "      <th>I-fromloc.city_name</th>\n",
       "      <th>I-arrive_time.time</th>\n",
       "      <th>I-toloc.city_name</th>\n",
       "      <th>I-stoploc.city_name</th>\n",
       "      <th>I-airline_name</th>\n",
       "      <th>I-toloc.airport_name</th>\n",
       "      <th>...</th>\n",
       "      <th>I-depart_date.today_relative</th>\n",
       "      <th>I-fare_basis_code</th>\n",
       "      <th>I-arrive_time.start_time</th>\n",
       "      <th>I-today_relative</th>\n",
       "      <th>I-depart_time.period_of_day</th>\n",
       "      <th>I-arrive_time.time_relative</th>\n",
       "      <th>I-time</th>\n",
       "      <th>I-depart_time.time_relative</th>\n",
       "      <th>I-return_date.today_relative</th>\n",
       "      <th>I-meal_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to fly from baltimore to dallas round ...</td>\n",
       "      <td>[I-round_trip]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>round trip fares from baltimore to philadelph...</td>\n",
       "      <td>[I-round_trip, I-fare_amount, I-round_trip, I-...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>show me the flights arriving on baltimore on ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are the flights which depart from san fr...</td>\n",
       "      <td>[I-fromloc.city_name, I-arrive_time.time]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which airlines fly from boston to washington ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0   i want to fly from baltimore to dallas round ...   \n",
       "1   round trip fares from baltimore to philadelph...   \n",
       "2   show me the flights arriving on baltimore on ...   \n",
       "3   what are the flights which depart from san fr...   \n",
       "4   which airlines fly from boston to washington ...   \n",
       "\n",
       "                                         intent_list  I-round_trip  \\\n",
       "0                                     [I-round_trip]             1   \n",
       "1  [I-round_trip, I-fare_amount, I-round_trip, I-...             1   \n",
       "2                                                 []             0   \n",
       "3          [I-fromloc.city_name, I-arrive_time.time]             0   \n",
       "4                                                 []             0   \n",
       "\n",
       "   I-fare_amount  I-fromloc.city_name  I-arrive_time.time  I-toloc.city_name  \\\n",
       "0              0                    0                   0                  0   \n",
       "1              1                    0                   0                  0   \n",
       "2              0                    0                   0                  0   \n",
       "3              0                    1                   1                  0   \n",
       "4              0                    0                   0                  0   \n",
       "\n",
       "   I-stoploc.city_name  I-airline_name  I-toloc.airport_name  \\\n",
       "0                    0               0                     0   \n",
       "1                    0               0                     0   \n",
       "2                    0               0                     0   \n",
       "3                    0               0                     0   \n",
       "4                    0               0                     0   \n",
       "\n",
       "          ...          I-depart_date.today_relative  I-fare_basis_code  \\\n",
       "0         ...                                     0                  0   \n",
       "1         ...                                     0                  0   \n",
       "2         ...                                     0                  0   \n",
       "3         ...                                     0                  0   \n",
       "4         ...                                     0                  0   \n",
       "\n",
       "   I-arrive_time.start_time  I-today_relative  I-depart_time.period_of_day  \\\n",
       "0                         0                 0                            0   \n",
       "1                         0                 0                            0   \n",
       "2                         0                 0                            0   \n",
       "3                         0                 0                            0   \n",
       "4                         0                 0                            0   \n",
       "\n",
       "   I-arrive_time.time_relative  I-time  I-depart_time.time_relative  \\\n",
       "0                            0       0                            0   \n",
       "1                            0       0                            0   \n",
       "2                            0       0                            0   \n",
       "3                            0       0                            0   \n",
       "4                            0       0                            0   \n",
       "\n",
       "   I-return_date.today_relative  I-meal_description  \n",
       "0                             0                   0  \n",
       "1                             0                   0  \n",
       "2                             0                   0  \n",
       "3                             0                   0  \n",
       "4                             0                   0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreProcessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def tokenize(self, line):\n",
    "        \"\"\" Tokenize every words from sentence\"\"\"\n",
    "        tokens = nltk.word_tokenize(line)\n",
    "        return tokens\n",
    "\n",
    "    def to_lower(self, line):\n",
    "        \"\"\" Convert words from line to lower case\"\"\"\n",
    "        words = [word.lower() for word in line]\n",
    "        return words\n",
    "\n",
    "    def remove_punctuation(self, line):\n",
    "        \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "        new_words = []\n",
    "        for word in line:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "        return new_words\n",
    "\n",
    "    def remove_stop_words(self, line):\n",
    "        \"\"\" Remove stop words\"\"\"\n",
    "        words = [word for word in line if word not in stopwords.words('english')]\n",
    "        return words\n",
    "\n",
    "    def lemmatize_words(self, line):\n",
    "        \"\"\"Lemmatize tokens in list of tokenized words\"\"\"\n",
    "        # lemmatizer = WordNetLemmatizer()\n",
    "        lemmas = [self.lemmatizer.lemmatize(word) for word in line]\n",
    "        return lemmas\n",
    "    \n",
    "    def clean_text (self, data):\n",
    "        clean_sent = data['sentences'].apply(lambda x: self.tokenize(x))\n",
    "        clean_sent = clean_sent.apply(lambda x: self.to_lower(x))\n",
    "        clean_sent = clean_sent.apply(lambda x: self.remove_punctuation(x))\n",
    "        clean_sent = clean_sent.apply(lambda x: self.remove_stop_words(x))\n",
    "        clean_sent = clean_sent.apply(lambda x: self.lemmatize_words(x))\n",
    "        return list(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = TextPreProcessor()\n",
    "clean_sent = preprocess.clean_text(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4478\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading google pre-trained model for word2vec\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"./model/GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        print(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute similarity with no input %s ['ewr']\n",
      "cannot compute similarity with no input %s ['mco']\n",
      "cannot compute similarity with no input %s []\n",
      "cannot compute similarity with no input %s ['ewr']\n",
      "cannot compute similarity with no input %s ['mco']\n",
      "cannot compute similarity with no input %s ['mco']\n",
      "cannot compute similarity with no input %s ['ewr']\n",
      "cannot compute similarity with no input %s ['yyz']\n",
      "cannot compute similarity with no input %s ['ewr']\n",
      "cannot compute similarity with no input %s ['mco']\n",
      "cannot compute similarity with no input %s ['ewr']\n",
      "cannot compute similarity with no input %s ['bna']\n"
     ]
    }
   ],
   "source": [
    "X = word_averaging_list(wv, clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4478, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(data, X, unique_intents, modelname):\n",
    "    \"\"\" Train a base model with minimal tuning for comparision \"\"\"\n",
    "    for intent in unique_intents:\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X, np.array(data[intent]))\n",
    "        joblib.dump(model, \"./model/{0}_{1}.pkl\".format(intent,modelname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    \"\"\"Calculate all the evaluation metrics of classification model\"\"\"\n",
    "    cm = m.confusion_matrix(y_true, y_pred)\n",
    "    acc = m.accuracy_score(y_true, y_pred)\n",
    "    prec = m.precision_score(y_true, y_pred)\n",
    "    recall = m.recall_score(y_true, y_pred)\n",
    "    f1score = m.f1_score(y_true, y_pred)\n",
    "    evaluation = {\"accuracy\": round(float(acc)*100,2),\n",
    "                  \"precision\":round(float(prec)*100,2),\n",
    "                  \"recall\":round(float(recall)*100,2),\n",
    "                  \"f1_score\":round(float(f1score)*100,2)}\n",
    "    return evaluation, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(modelname, X_test, data,train_intents, test_intents):\n",
    "    \"\"\" Test the model performance on test data\"\"\"\n",
    "    y_pred, confusion_mat, evaluation = {},{},{}\n",
    "    for intent in train_intents:\n",
    "        if intent in test_intents:\n",
    "            model = joblib.load(\"./model/{0}_{1}.pkl\".format(intent, modelname))\n",
    "            print(\"./model/{0}_{1}.pkl\".format(intent, modelname))\n",
    "            test_eval, cm = evaluate_classification(np.array(data[intent]), model.predict(X_test))\n",
    "            confusion_mat[intent] = cm\n",
    "            evaluation[intent] = test_eval\n",
    "    return confusion_mat, evaluation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(train_data, X, unique_intents, \"base_rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, unique_intents_test = create_dataframe(\"./data/atis.test.w-intent.iob.txt\")\n",
    "# comparision = set(unique_intents) -set(unique_intents_test)\n",
    "# print(comparision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n",
      "WARNING:root:cannot compute similarity with no input ['phl']\n",
      "WARNING:root:cannot compute similarity with no input ['mci']\n",
      "WARNING:root:cannot compute similarity with no input ['d9s']\n",
      "WARNING:root:cannot compute similarity with no input ['d9s']\n",
      "WARNING:root:cannot compute similarity with no input ['73s']\n",
      "WARNING:root:cannot compute similarity with no input ['cvg']\n"
     ]
    }
   ],
   "source": [
    "clean_test_sent = preprocess.clean_text(test_data)\n",
    "X_test = word_averaging_list(wv, clean_test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/I-round_trip_base_rf.pkl\n",
      "{'I-round_trip': array([[822,   0],\n",
      "       [ 36,  35]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "con_mat, evaluation = test_model(\"base_rf\", X_test, test_data,unique_intents, unique_intents_test)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           I-round_trip\n",
      "accuracy          95.97\n",
      "f1_score          66.04\n",
      "precision        100.00\n",
      "recall            49.30\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter():  \n",
    "    \"\"\" Define the hyper parameters for random forest\"\"\"\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\\\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 100, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True, False]\n",
    "    return {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_hyper(data, X, unique_intents, modelname):\n",
    "    \"\"\" Train a Random Forest model with tuning the the hyperparameter using random search\"\"\"\n",
    "    for intent in unique_intents:\n",
    "        rf = RandomForestClassifier()\n",
    "        rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = hyper_parameter(), cv = 5, \n",
    "                               verbose=2, random_state=42, n_jobs = -1)\n",
    "        rf_random.fit(X, np.array(data[intent]))\n",
    "        best_model = rf_random.best_estimator_\n",
    "        joblib.dump(best_model, \"./model/{0}_{1}.pkl\".format(intent,modelname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "model_train_hyper(train_data, X, unique_intents, \"rf_random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = [\"I-airline_name\",\"I-arrive_time.time\",\"I-class_type\",\"I-cost_relative\",\"I-depart_time.time\",\"I-fare_amount\",\n",
    "                \"I-fromloc.airport_name\",\"I-fromloc.city_name\",\"I-round_trip\",\"I-stoploc.city_name\",\"I-toloc.airport_name\",\"I-toloc.city_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/I-airline_name_rf_random.pkl\n",
      "./model/I-arrive_time.time_rf_random.pkl\n",
      "./model/I-class_type_rf_random.pkl\n",
      "./model/I-cost_relative_rf_random.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Manish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/I-depart_time.time_rf_random.pkl\n",
      "./model/I-fare_amount_rf_random.pkl\n",
      "./model/I-fromloc.airport_name_rf_random.pkl\n",
      "./model/I-fromloc.city_name_rf_random.pkl\n",
      "./model/I-round_trip_rf_random.pkl\n",
      "./model/I-stoploc.city_name_rf_random.pkl\n",
      "./model/I-toloc.airport_name_rf_random.pkl\n",
      "./model/I-toloc.city_name_rf_random.pkl\n",
      "{'I-airline_name': array([[833,   0],\n",
      "       [ 44,  16]], dtype=int64), 'I-arrive_time.time': array([[858,   1],\n",
      "       [ 26,   8]], dtype=int64), 'I-class_type': array([[876,   0],\n",
      "       [  2,  15]], dtype=int64), 'I-cost_relative': array([[890,   0],\n",
      "       [  3,   0]], dtype=int64), 'I-depart_time.time': array([[839,   2],\n",
      "       [ 48,   4]], dtype=int64), 'I-fare_amount': array([[891,   0],\n",
      "       [  2,   0]], dtype=int64), 'I-fromloc.airport_name': array([[881,   1],\n",
      "       [ 10,   1]], dtype=int64), 'I-fromloc.city_name': array([[725,   4],\n",
      "       [133,  31]], dtype=int64), 'I-round_trip': array([[822,   0],\n",
      "       [ 26,  45]], dtype=int64), 'I-stoploc.city_name': array([[883,   0],\n",
      "       [ 10,   0]], dtype=int64), 'I-toloc.airport_name': array([[890,   0],\n",
      "       [  3,   0]], dtype=int64), 'I-toloc.city_name': array([[649,  28],\n",
      "       [110, 106]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "con_mat_best, evaluation_best = test_model(\"rf_random\", X_test, test_data, trained_model,unique_intents_test)\n",
    "print(con_mat_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           I-airline_name  I-arrive_time.time  I-class_type  I-cost_relative  \\\n",
      "accuracy            95.07               96.98         99.78            99.66   \n",
      "f1_score            42.11               37.21         93.75             0.00   \n",
      "precision          100.00               88.89        100.00             0.00   \n",
      "recall              26.67               23.53         88.24             0.00   \n",
      "\n",
      "           I-depart_time.time  I-fare_amount  I-fromloc.airport_name  \\\n",
      "accuracy                94.40          99.78                   98.77   \n",
      "f1_score                13.79           0.00                   15.38   \n",
      "precision               66.67           0.00                   50.00   \n",
      "recall                   7.69           0.00                    9.09   \n",
      "\n",
      "           I-fromloc.city_name  I-round_trip  I-stoploc.city_name  \\\n",
      "accuracy                 84.66         97.09                98.88   \n",
      "f1_score                 31.16         77.59                 0.00   \n",
      "precision                88.57        100.00                 0.00   \n",
      "recall                   18.90         63.38                 0.00   \n",
      "\n",
      "           I-toloc.airport_name  I-toloc.city_name  \n",
      "accuracy                  99.66              84.55  \n",
      "f1_score                   0.00              60.57  \n",
      "precision                  0.00              79.10  \n",
      "recall                     0.00              49.07  \n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(evaluation_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
